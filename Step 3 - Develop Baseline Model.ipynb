{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Step 3 - Develop Baseline Demand Prediction Model\n",
    "\n",
    "With Steps 1 and 2 complete, we are ready to create a baseline model for for predicting demand. Generally, we create baseline model using very basic techniques like mean prediction and then we try more complex solutions to improve the results that we got from the baseline model.\n",
    "\n",
    "---\n",
    "In this Notebook:\n",
    " - We will first of all predict the target using the mean of previous data. For, a particular store, how many average number of units were sold of a particular product.\n",
    " - We will create a Regression based model and Tree based model.\n",
    " - We will use Simple Moving Average (a very basic Time Series Model).\n",
    " - We will use data to train model with different time periods and check whether there is a recency factor in our data.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import datasets.\n",
    "salesdf = pd.read_csv('data/salesdf.csv')\n",
    "productsdf = pd.read_csv('data/productsdf.csv')\n",
    "storesdf = pd.read_csv('data/storesdf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WEEK_END_DATE</th>\n",
       "      <th>STORE_NUM</th>\n",
       "      <th>UPC</th>\n",
       "      <th>PRICE</th>\n",
       "      <th>BASE_PRICE</th>\n",
       "      <th>FEATURE</th>\n",
       "      <th>DISPLAY</th>\n",
       "      <th>UNITS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>13-Jan-16</td>\n",
       "      <td>367</td>\n",
       "      <td>1111009477</td>\n",
       "      <td>1.39</td>\n",
       "      <td>1.57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>13-Jan-16</td>\n",
       "      <td>367</td>\n",
       "      <td>1111009497</td>\n",
       "      <td>1.39</td>\n",
       "      <td>1.39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>13-Jan-16</td>\n",
       "      <td>367</td>\n",
       "      <td>1111085319</td>\n",
       "      <td>1.88</td>\n",
       "      <td>1.88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>13-Jan-16</td>\n",
       "      <td>367</td>\n",
       "      <td>1111085345</td>\n",
       "      <td>1.88</td>\n",
       "      <td>1.88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>13-Jan-16</td>\n",
       "      <td>367</td>\n",
       "      <td>1111085350</td>\n",
       "      <td>1.98</td>\n",
       "      <td>1.98</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  WEEK_END_DATE  STORE_NUM         UPC  PRICE  BASE_PRICE  FEATURE  DISPLAY  \\\n",
       "0     13-Jan-16        367  1111009477   1.39        1.57        0        0   \n",
       "1     13-Jan-16        367  1111009497   1.39        1.39        0        0   \n",
       "2     13-Jan-16        367  1111085319   1.88        1.88        0        0   \n",
       "3     13-Jan-16        367  1111085345   1.88        1.88        0        0   \n",
       "4     13-Jan-16        367  1111085350   1.98        1.98        0        0   \n",
       "\n",
       "   UNITS  \n",
       "0     13  \n",
       "1     20  \n",
       "2     14  \n",
       "3     29  \n",
       "4     35  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salesdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UPC</th>\n",
       "      <th>MANUFACTURER_1</th>\n",
       "      <th>MANUFACTURER_2</th>\n",
       "      <th>MANUFACTURER_3</th>\n",
       "      <th>MANUFACTURER_4</th>\n",
       "      <th>MANUFACTURER_5</th>\n",
       "      <th>MANUFACTURER_6</th>\n",
       "      <th>MANUFACTURER_7</th>\n",
       "      <th>MANUFACTURER_8</th>\n",
       "      <th>MANUFACTURER_9</th>\n",
       "      <th>...</th>\n",
       "      <th>CATEGORY_3</th>\n",
       "      <th>CATEGORY_4</th>\n",
       "      <th>SUB_CATEGORY_1</th>\n",
       "      <th>SUB_CATEGORY_2</th>\n",
       "      <th>SUB_CATEGORY_3</th>\n",
       "      <th>SUB_CATEGORY_4</th>\n",
       "      <th>SUB_CATEGORY_5</th>\n",
       "      <th>SUB_CATEGORY_6</th>\n",
       "      <th>SUB_CATEGORY_7</th>\n",
       "      <th>PRODUCT_SIZE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1111009477</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1111009497</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1111009507</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1111038078</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1111038080</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          UPC  MANUFACTURER_1  MANUFACTURER_2  MANUFACTURER_3  MANUFACTURER_4  \\\n",
       "0  1111009477               1               0               0               0   \n",
       "1  1111009497               1               0               0               0   \n",
       "2  1111009507               1               0               0               0   \n",
       "3  1111038078               1               0               0               0   \n",
       "4  1111038080               1               0               0               0   \n",
       "\n",
       "   MANUFACTURER_5  MANUFACTURER_6  MANUFACTURER_7  MANUFACTURER_8  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               0               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   MANUFACTURER_9  ...  CATEGORY_3  CATEGORY_4  SUB_CATEGORY_1  \\\n",
       "0               0  ...           0           0               1   \n",
       "1               0  ...           0           0               1   \n",
       "2               0  ...           0           0               1   \n",
       "3               0  ...           0           0               0   \n",
       "4               0  ...           0           0               0   \n",
       "\n",
       "   SUB_CATEGORY_2  SUB_CATEGORY_3  SUB_CATEGORY_4  SUB_CATEGORY_5  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               0               0   \n",
       "2               0               0               0               0   \n",
       "3               1               0               0               0   \n",
       "4               1               0               0               0   \n",
       "\n",
       "   SUB_CATEGORY_6  SUB_CATEGORY_7  PRODUCT_SIZE  \n",
       "0               0               0             2  \n",
       "1               0               0             2  \n",
       "2               0               0             2  \n",
       "3               0               0             1  \n",
       "4               0               0             1  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "productsdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STORE_ID</th>\n",
       "      <th>ADDRESS_STATE_PROV_CODE_1</th>\n",
       "      <th>ADDRESS_STATE_PROV_CODE_2</th>\n",
       "      <th>ADDRESS_STATE_PROV_CODE_3</th>\n",
       "      <th>ADDRESS_STATE_PROV_CODE_4</th>\n",
       "      <th>MSA_CODE_1</th>\n",
       "      <th>MSA_CODE_2</th>\n",
       "      <th>MSA_CODE_3</th>\n",
       "      <th>MSA_CODE_4</th>\n",
       "      <th>MSA_CODE_5</th>\n",
       "      <th>MSA_CODE_6</th>\n",
       "      <th>MSA_CODE_7</th>\n",
       "      <th>MSA_CODE_8</th>\n",
       "      <th>MSA_CODE_9</th>\n",
       "      <th>SEG_VALUE_NAME</th>\n",
       "      <th>SALES_AREA_SIZE_NUM</th>\n",
       "      <th>AVG_WEEKLY_BASKETS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>367</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>24721</td>\n",
       "      <td>12707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>389</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>46073</td>\n",
       "      <td>24767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>613</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>64926</td>\n",
       "      <td>29386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>623</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>46930</td>\n",
       "      <td>36741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2277</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>81958</td>\n",
       "      <td>54053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   STORE_ID  ADDRESS_STATE_PROV_CODE_1  ADDRESS_STATE_PROV_CODE_2  \\\n",
       "0       367                          1                          0   \n",
       "1       389                          1                          0   \n",
       "2       613                          0                          1   \n",
       "3       623                          0                          1   \n",
       "4      2277                          0                          0   \n",
       "\n",
       "   ADDRESS_STATE_PROV_CODE_3  ADDRESS_STATE_PROV_CODE_4  MSA_CODE_1  \\\n",
       "0                          0                          0           1   \n",
       "1                          0                          0           1   \n",
       "2                          0                          0           0   \n",
       "3                          0                          0           0   \n",
       "4                          1                          0           1   \n",
       "\n",
       "   MSA_CODE_2  MSA_CODE_3  MSA_CODE_4  MSA_CODE_5  MSA_CODE_6  MSA_CODE_7  \\\n",
       "0           0           0           0           0           0           0   \n",
       "1           0           0           0           0           0           0   \n",
       "2           1           0           0           0           0           0   \n",
       "3           0           1           0           0           0           0   \n",
       "4           0           0           0           0           0           0   \n",
       "\n",
       "   MSA_CODE_8  MSA_CODE_9  SEG_VALUE_NAME  SALES_AREA_SIZE_NUM  \\\n",
       "0           0           0               1                24721   \n",
       "1           0           0               2                46073   \n",
       "2           0           0               2                64926   \n",
       "3           0           0               2                46930   \n",
       "4           0           0               3                81958   \n",
       "\n",
       "   AVG_WEEKLY_BASKETS  \n",
       "0               12707  \n",
       "1               24767  \n",
       "2               29386  \n",
       "3               36741  \n",
       "4               54053  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "storesdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge datasets.\n",
    "basemodel = salesdf.merge(productsdf, how='left', on= 'UPC')\n",
    "basemodel = basemodel.merge(storesdf, how= 'left', left_on= 'STORE_NUM', right_on= 'STORE_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "basemodel = basemodel.drop(columns=['STORE_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for null values in dataset.\n",
    "basemodel.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WEEK_END_DATE                 13-Jan-16\n",
       "STORE_NUM                           367\n",
       "UPC                          1111009477\n",
       "PRICE                              1.39\n",
       "BASE_PRICE                         1.57\n",
       "FEATURE                               0\n",
       "DISPLAY                               0\n",
       "UNITS                                13\n",
       "MANUFACTURER_1                        1\n",
       "MANUFACTURER_2                        0\n",
       "MANUFACTURER_3                        0\n",
       "MANUFACTURER_4                        0\n",
       "MANUFACTURER_5                        0\n",
       "MANUFACTURER_6                        0\n",
       "MANUFACTURER_7                        0\n",
       "MANUFACTURER_8                        0\n",
       "MANUFACTURER_9                        0\n",
       "CATEGORY_1                            1\n",
       "CATEGORY_2                            0\n",
       "CATEGORY_3                            0\n",
       "CATEGORY_4                            0\n",
       "SUB_CATEGORY_1                        1\n",
       "SUB_CATEGORY_2                        0\n",
       "SUB_CATEGORY_3                        0\n",
       "SUB_CATEGORY_4                        0\n",
       "SUB_CATEGORY_5                        0\n",
       "SUB_CATEGORY_6                        0\n",
       "SUB_CATEGORY_7                        0\n",
       "PRODUCT_SIZE                          2\n",
       "ADDRESS_STATE_PROV_CODE_1             1\n",
       "ADDRESS_STATE_PROV_CODE_2             0\n",
       "ADDRESS_STATE_PROV_CODE_3             0\n",
       "ADDRESS_STATE_PROV_CODE_4             0\n",
       "MSA_CODE_1                            1\n",
       "MSA_CODE_2                            0\n",
       "MSA_CODE_3                            0\n",
       "MSA_CODE_4                            0\n",
       "MSA_CODE_5                            0\n",
       "MSA_CODE_6                            0\n",
       "MSA_CODE_7                            0\n",
       "MSA_CODE_8                            0\n",
       "MSA_CODE_9                            0\n",
       "SEG_VALUE_NAME                        1\n",
       "SALES_AREA_SIZE_NUM               24721\n",
       "AVG_WEEKLY_BASKETS                12707\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basemodel.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the WEEK_END_DATE to datetime format.\n",
    "basemodel.WEEK_END_DATE = pd.to_datetime(basemodel.WEEK_END_DATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "- Store unique `WEEK_END_DATE` values in a list to more easily split the data based on datetime, which is required to split data into train and validation datasets.\n",
    "\n",
    "- Create a one-week gap between the train and validation datasets, with the train set starting from the very begining of the dates in our model.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store unique dates in a list.\n",
    "weeks = basemodel.WEEK_END_DATE.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function that will return a dictionary which contains keys. There will be 1 week gap between train and validation datasets.\n",
    "\n",
    "def get_train_validation_set(number=1):\n",
    "    validation_sets = []\n",
    "    for n in range(number):\n",
    "        x = {}\n",
    "        \n",
    "        x['validation_set'] = weeks[len(weeks)-n-1]\n",
    "        x['train_set_end_date'] = weeks[len(weeks)-n-3]\n",
    "        validation_sets.append(x)\n",
    "        \n",
    "    return validation_sets       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create baseline model and test on 5 different datasets in order to check the consistency of Baseline RMSLE scores across multiple subsets of data. \n",
    "validation_sets = get_train_validation_set(number=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'validation_set': numpy.datetime64('2018-09-26T00:00:00.000000000'),\n",
       "  'train_set_end_date': numpy.datetime64('2018-09-12T00:00:00.000000000')},\n",
       " {'validation_set': numpy.datetime64('2018-09-19T00:00:00.000000000'),\n",
       "  'train_set_end_date': numpy.datetime64('2018-09-05T00:00:00.000000000')},\n",
       " {'validation_set': numpy.datetime64('2018-09-12T00:00:00.000000000'),\n",
       "  'train_set_end_date': numpy.datetime64('2018-08-29T00:00:00.000000000')},\n",
       " {'validation_set': numpy.datetime64('2018-09-05T00:00:00.000000000'),\n",
       "  'train_set_end_date': numpy.datetime64('2018-08-22T00:00:00.000000000')},\n",
       " {'validation_set': numpy.datetime64('2018-08-29T00:00:00.000000000'),\n",
       "  'train_set_end_date': numpy.datetime64('2018-08-15T00:00:00.000000000')}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine dictionary created.\n",
    "validation_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use dictionary and store train and validation sets as a list of tuples.\n",
    "\n",
    "data_set = []\n",
    "\n",
    "for data in validation_sets:\n",
    "    \n",
    "    traindf = basemodel[basemodel.WEEK_END_DATE <= data['train_set_end_date']]\n",
    "    validatedf = basemodel[basemodel.WEEK_END_DATE == data['validation_set']]\n",
    "    \n",
    "    data_set.append((traindf, validatedf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Baseline #1: Mean Prediction\n",
    "\n",
    "\n",
    "Now, we will create our first baseline model, `MEAN PREDICTION`. We will use the past data to and take average on a group of `STORE_NUM` and `UPC` and use this to predict on the validaion set.\n",
    "\n",
    "\n",
    "#### `Evaluation Metric: ` Root Mean Squared Log Error (RMSLE)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to get the RMSLE.\n",
    "from sklearn.metrics import mean_squared_log_error as msle\n",
    "\n",
    "def get_msle(true, predicted) :\n",
    "    return np.sqrt(msle( true, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE ON TRAINING SET:  1 :  0.5902468460088598\n",
      "RMSLE ON VALIDATION SET:  1 :  0.5887816704436897\n",
      "=====================================================================\n",
      "RMSLE ON TRAINING SET:  2 :  0.591251579931832\n",
      "RMSLE ON VALIDATION SET:  2 :  0.6263156060802706\n",
      "=====================================================================\n",
      "RMSLE ON TRAINING SET:  3 :  0.5917841764867795\n",
      "RMSLE ON VALIDATION SET:  3 :  0.47837118281730495\n",
      "=====================================================================\n",
      "RMSLE ON TRAINING SET:  4 :  0.5914233373769653\n",
      "RMSLE ON VALIDATION SET:  4 :  0.5811759211472836\n",
      "=====================================================================\n",
      "RMSLE ON TRAINING SET:  5 :  0.5916269229162222\n",
      "RMSLE ON VALIDATION SET:  5 :  0.718159952727328\n",
      "=====================================================================\n",
      "Mean RMSLE on Train:  0.5912665725441318\n",
      "Mean RMSLE on Valid:  0.5985608666431753\n"
     ]
    }
   ],
   "source": [
    "train_rmsle = []\n",
    "valid_rmsle = []\n",
    "\n",
    "for i, data in enumerate(data_set):\n",
    "    \n",
    "    # get the train and validation set\n",
    "    train, valid = data\n",
    "    \n",
    "    # get the mean prediction dataframe by using a groupby on STORE_NUM and UPC\n",
    "    mean_prediction = train.groupby(['STORE_NUM', 'UPC'])['UNITS'].mean().reset_index()\n",
    "    \n",
    "    # left join the train and validation set with the mean prediction.\n",
    "    train = train.merge(mean_prediction, how='left', on=['STORE_NUM', 'UPC'])\n",
    "    valid = valid.merge(mean_prediction, how='left', on=['STORE_NUM', 'UPC'])\n",
    "    \n",
    "    # In the updated dataframe after the left join, \n",
    "    # column UNITS_x is the original value of the target variable\n",
    "    # column UNITS_y is the predicted value of the target variable\n",
    "    \n",
    "    \n",
    "    # get the rmsle on train and validation set\n",
    "    t_rmsle = get_msle(train.UNITS_x, train.UNITS_y)\n",
    "    v_rmsle = get_msle(valid.UNITS_x, valid.UNITS_y)\n",
    "    train_rmsle.append(t_rmsle)\n",
    "    valid_rmsle.append(v_rmsle)\n",
    "    \n",
    "    print('RMSLE ON TRAINING SET: ',i+1, ': ', t_rmsle)\n",
    "    print('RMSLE ON VALIDATION SET: ',i+1, ': ',v_rmsle)\n",
    "    print('=====================================================================')\n",
    "    \n",
    "# get the mean RMSLE on train and validation set.     \n",
    "print('Mean RMSLE on Train: ', np.mean(train_rmsle))\n",
    "print('Mean RMSLE on Valid: ', np.mean(valid_rmsle))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **This result is just ok. We need to try more models to see how it compares.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Baseline #2 - Simple Moving Average\n",
    "\n",
    "- The predicted value will be the average number of UNITS sold in last 8 weeks from a particular store for a particular product.\n",
    "- As, we have one week gap between the train and validation set. So the last week prediction values in the training set will be used as the prediction values for the validation set.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sma(i, train, valid, no_of_weeks=2):\n",
    "    \n",
    "    # create a copy of train and validation set\n",
    "    train_copy = train.copy()\n",
    "    valid_copy = valid.copy()\n",
    "    \n",
    "    # group the data by STORE_NUM and UPC and use rolling and mean function to calculate the moving average.\n",
    "    data_copy = train_copy.groupby(['STORE_NUM','UPC'])['UNITS'].rolling(no_of_weeks).mean().reset_index().set_index('level_2')\n",
    "    \n",
    "    # add the moving average column to the train data\n",
    "    train_copy['moving_average'] = data_copy['UNITS']\n",
    "    \n",
    "    # the last prediction on train set will be used as prediciton on validation set.\n",
    "    # calculate the last_average dataframe by groupby using last function.\n",
    "    last_average = train_copy.groupby(['STORE_NUM', 'UPC'])['moving_average'].last().reset_index()\n",
    "    \n",
    "    train_copy = train_copy[['WEEK_END_DATE', 'STORE_NUM', 'UPC', 'UNITS', 'moving_average']]\n",
    "    valid_copy = valid_copy[['WEEK_END_DATE','STORE_NUM', 'UPC', 'UNITS']]\n",
    "    \n",
    "    # drop the null values in the dataframe\n",
    "    train_copy.dropna(inplace=True)\n",
    "    # merge the validation data with the last_average by left join\n",
    "    valid_copy = valid_copy.merge(last_average, how= 'left', on= ['STORE_NUM', 'UPC'])\n",
    "    \n",
    "    # calculate the rmsle on train and validation data\n",
    "    t_rmsle = get_msle(train_copy['UNITS'], train_copy['moving_average'])\n",
    "    v_rmsle = get_msle(valid_copy['UNITS'], valid_copy['moving_average'])\n",
    "       \n",
    "        \n",
    "    print('RMSLE ON TRAINING SET: ',i+1, ': ', t_rmsle)\n",
    "    print('RMSLE ON VALIDATION SET: ',i+1, ': ',v_rmsle)\n",
    "    print('=====================================================================')\n",
    "    \n",
    "    return t_rmsle, v_rmsle\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE ON TRAINING SET:  1 :  0.532290520757075\n",
      "RMSLE ON VALIDATION SET:  1 :  0.5469206496913668\n",
      "=====================================================================\n",
      "RMSLE ON TRAINING SET:  2 :  0.5332313430963387\n",
      "RMSLE ON VALIDATION SET:  2 :  0.6421015703332319\n",
      "=====================================================================\n",
      "RMSLE ON TRAINING SET:  3 :  0.5335581839226429\n",
      "RMSLE ON VALIDATION SET:  3 :  0.46149085909723564\n",
      "=====================================================================\n",
      "RMSLE ON TRAINING SET:  4 :  0.5324765840327685\n",
      "RMSLE ON VALIDATION SET:  4 :  0.5878031103068386\n",
      "=====================================================================\n",
      "RMSLE ON TRAINING SET:  5 :  0.5318645623862213\n",
      "RMSLE ON VALIDATION SET:  5 :  0.7558881602487321\n",
      "=====================================================================\n",
      "Mean RMSLE on Train:  0.5326842388390093\n",
      "Mean RMSLE on Valid:  0.598840869935481\n"
     ]
    }
   ],
   "source": [
    "train_rmsle_ma = []\n",
    "valid_rmsle_ma = []\n",
    "\n",
    "for i, data in enumerate(data_set):\n",
    "    train, valid = data\n",
    "\n",
    "    t_rmsle, v_rmsle = get_sma(i,train, valid, no_of_weeks=8)\n",
    "    train_rmsle_ma.append(t_rmsle)\n",
    "    valid_rmsle_ma.append(v_rmsle)\n",
    "    \n",
    "print('Mean RMSLE on Train: ', np.mean(train_rmsle_ma))\n",
    "print('Mean RMSLE on Valid: ', np.mean(valid_rmsle_ma))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **This model didn't perform much better than the Mean Prediction model.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Linear Regresssion\n",
    "\n",
    "- Now, we will try one Regression Based Model and see how it performs on our dataset. We will use the same 5 validation sets and compare the results. \n",
    "- Keys `WEEK_END_DATE`, `STORE_NUM` and `UPC` will be dropped.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE ON TRAINING SET:  1 :  0.9856560459029289\n",
      "RMSLE ON VALIDATION SET:  1 :  0.9466737000535473\n",
      "=====================================================================\n",
      "RMSLE ON TRAINING SET:  2 :  0.9854516120683233\n",
      "RMSLE ON VALIDATION SET:  2 :  0.9276683506412722\n",
      "=====================================================================\n",
      "RMSLE ON TRAINING SET:  3 :  0.9904294711153601\n",
      "RMSLE ON VALIDATION SET:  3 :  0.9593632305560731\n",
      "=====================================================================\n",
      "RMSLE ON TRAINING SET:  4 :  0.978111045337829\n",
      "RMSLE ON VALIDATION SET:  4 :  0.9119993845391732\n",
      "=====================================================================\n",
      "RMSLE ON TRAINING SET:  5 :  0.988499547504901\n",
      "RMSLE ON VALIDATION SET:  5 :  0.9615990929915409\n",
      "=====================================================================\n",
      "Mean RMSLE on Train:  0.9856295443858685\n",
      "Mean RMSLE on Valid:  0.9414607517563214\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "train_rmsle_lr = []\n",
    "valid_rmsle_lr = []\n",
    "\n",
    "for i, data in enumerate(data_set):\n",
    "    \n",
    "    train, valid = data\n",
    "    \n",
    "    # drop the columns that are not required, separate the target and independent features\n",
    "    train_x = train.drop(columns=['WEEK_END_DATE', 'STORE_NUM', 'UPC', 'UNITS'])\n",
    "    train_y = train['UNITS']\n",
    "    \n",
    "    valid_x = valid.drop(columns=['WEEK_END_DATE', 'STORE_NUM', 'UPC', 'UNITS'])\n",
    "    valid_y = valid['UNITS']\n",
    "    \n",
    "    # create an Object of the Linear Regression model\n",
    "    model_LR = LinearRegression(normalize=True)\n",
    "    # fit the model with  the training data\n",
    "    model_LR.fit(train_x, train_y)\n",
    "    \n",
    "    # predict on the training data \n",
    "    # the model can predict some negative values also and RMSLE only supports positive values.\n",
    "    # So, we will use the clip function. It will convert all the negative predicted values to 0.\n",
    "    predict_train = model_LR.predict(train_x).clip(min=0)\n",
    "    predict_valid = model_LR.predict(valid_x).clip(min=0)\n",
    "    \n",
    "    # get the rmsle on the training and validation data.\n",
    "    t_rmsle = get_msle(train_y, predict_train)\n",
    "    v_rmsle = get_msle(valid_y, predict_valid)\n",
    "    train_rmsle_lr.append(t_rmsle)\n",
    "    valid_rmsle_lr.append(v_rmsle)\n",
    "    \n",
    "    print('RMSLE ON TRAINING SET: ',i+1, ': ', t_rmsle)\n",
    "    print('RMSLE ON VALIDATION SET: ',i+1, ': ',v_rmsle)\n",
    "    print('=====================================================================')\n",
    "    \n",
    "    \n",
    "    \n",
    "print('Mean RMSLE on Train: ', np.mean(train_rmsle_lr))\n",
    "print('Mean RMSLE on Valid: ', np.mean(valid_rmsle_lr))    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Linear regression performed much worse than the other two baseline models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Baseline #4 - Decision Tree\n",
    "\n",
    "- Tree Based Model. We will use the same 5 validation sets and compare the results.\n",
    "- Again, keys `WEEK_END_DATE`, `STORE_NUM` and `UPC` will be dropped.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE ON TRAINING SET:  1 :  0.3509603160009687\n",
      "RMSLE ON VALIDATION SET:  1 :  0.45164333921186794\n",
      "=====================================================================\n",
      "RMSLE ON TRAINING SET:  2 :  0.35068405865135405\n",
      "RMSLE ON VALIDATION SET:  2 :  0.4818260918049475\n",
      "=====================================================================\n",
      "RMSLE ON TRAINING SET:  3 :  0.3502097858790728\n",
      "RMSLE ON VALIDATION SET:  3 :  0.45577650435346795\n",
      "=====================================================================\n",
      "RMSLE ON TRAINING SET:  4 :  0.34962464321046194\n",
      "RMSLE ON VALIDATION SET:  4 :  0.5072881470926939\n",
      "=====================================================================\n",
      "RMSLE ON TRAINING SET:  5 :  0.3496036689909416\n",
      "RMSLE ON VALIDATION SET:  5 :  0.5887580530350959\n",
      "=====================================================================\n",
      "Mean RMSLE on Train:  0.35021649454655984\n",
      "Mean RMSLE on Valid:  0.4970584270996146\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "train_rmsle_dtr = []\n",
    "valid_rmsle_dtr = []\n",
    "\n",
    "for i, data in enumerate(data_set):\n",
    "    \n",
    "    # get the train and validation set\n",
    "    train, valid = data\n",
    "    \n",
    "    # drop the columns that are not required, separate the target and independent features    \n",
    "    train_x = train.drop(columns=['WEEK_END_DATE', 'STORE_NUM', 'UPC', 'UNITS'])\n",
    "    train_y = train['UNITS']\n",
    "    \n",
    "    valid_x = valid.drop(columns=['WEEK_END_DATE', 'STORE_NUM', 'UPC', 'UNITS'])\n",
    "    valid_y = valid['UNITS']\n",
    "    \n",
    "    # create an Object of DecisionTree Regressor\n",
    "    model_DTR = DecisionTreeRegressor()\n",
    "    # fit the model with the training data\n",
    "    model_DTR.fit(train_x, train_y)\n",
    "    \n",
    "    # predict the target and set the minimum value of the predicted target variable to be 0\n",
    "    predict_train = model_DTR.predict(train_x).clip(min=0)\n",
    "    predict_valid = model_DTR.predict(valid_x).clip(min=0)\n",
    "    \n",
    "    # get the rmsle on train and validation set.\n",
    "    t_rmsle = get_msle(train_y, predict_train)\n",
    "    v_rmsle = get_msle(valid_y, predict_valid)\n",
    "    \n",
    "    train_rmsle_dtr.append(t_rmsle)\n",
    "    valid_rmsle_dtr.append(v_rmsle)\n",
    "    \n",
    "    print('RMSLE ON TRAINING SET: ',i+1, ': ', t_rmsle)\n",
    "    print('RMSLE ON VALIDATION SET: ',i+1, ': ',v_rmsle)\n",
    "    print('=====================================================================')\n",
    "    \n",
    "    \n",
    "    \n",
    "print('Mean RMSLE on Train: ', np.mean(train_rmsle_dtr))\n",
    "print('Mean RMSLE on Valid: ', np.mean(valid_rmsle_dtr))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Decision Tree performed much better than any of the previous linear baseline models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Baseline #5 - RandomForest\n",
    "\n",
    "Another Decision Tree based model. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE ON TRAINING SET:  1 :  0.3682865332962354\n",
      "RMSLE ON VALIDATION SET:  1 :  0.42012300710245326\n",
      "=====================================================================\n",
      "RMSLE ON TRAINING SET:  2 :  0.3681797274754799\n",
      "RMSLE ON VALIDATION SET:  2 :  0.4451762845496011\n",
      "=====================================================================\n",
      "RMSLE ON TRAINING SET:  3 :  0.3677729846864488\n",
      "RMSLE ON VALIDATION SET:  3 :  0.4337344871926344\n",
      "=====================================================================\n",
      "RMSLE ON TRAINING SET:  4 :  0.36738188410500855\n",
      "RMSLE ON VALIDATION SET:  4 :  0.48841969624697673\n",
      "=====================================================================\n",
      "RMSLE ON TRAINING SET:  5 :  0.367345916149398\n",
      "RMSLE ON VALIDATION SET:  5 :  0.557354356567105\n",
      "=====================================================================\n",
      "Mean RMSLE on Train:  0.3677934091425141\n",
      "Mean RMSLE on Valid:  0.4689615663317541\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "train_rmsle_dtr = []\n",
    "valid_rmsle_dtr = []\n",
    "\n",
    "for i, data in enumerate(data_set):\n",
    "    \n",
    "    # get the train and vaidation set\n",
    "    train, valid = data\n",
    "    \n",
    "    # drop the columns that are not required, separate the target and independent features     \n",
    "    train_x = train.drop(columns=['WEEK_END_DATE', 'STORE_NUM', 'UPC', 'UNITS'])\n",
    "    train_y = train['UNITS']\n",
    "    \n",
    "    valid_x = valid.drop(columns=['WEEK_END_DATE', 'STORE_NUM', 'UPC', 'UNITS'])\n",
    "    valid_y = valid['UNITS']\n",
    "    \n",
    "    # create an object of the Random Forest Regressor\n",
    "    model_DTR = RandomForestRegressor(random_state=0)\n",
    "    \n",
    "    # fit the model with the training data\n",
    "    model_DTR.fit(train_x, train_y)\n",
    "    \n",
    "    # predict the target and set the minimum value of the predicted target variable to be 0\n",
    "    predict_train = model_DTR.predict(train_x).clip(min=0)\n",
    "    predict_valid = model_DTR.predict(valid_x).clip(min=0)\n",
    "    \n",
    "    # get the rmsle on train and validate\n",
    "    t_rmsle = get_msle(train_y, predict_train)\n",
    "    v_rmsle = get_msle(valid_y, predict_valid)\n",
    "    \n",
    "    train_rmsle_dtr.append(t_rmsle)\n",
    "    valid_rmsle_dtr.append(v_rmsle)\n",
    "    \n",
    "    print('RMSLE ON TRAINING SET: ',i+1, ': ', t_rmsle)\n",
    "    print('RMSLE ON VALIDATION SET: ',i+1, ': ',v_rmsle)\n",
    "    print('=====================================================================')\n",
    "    \n",
    "    \n",
    "print('Mean RMSLE on Train: ', np.mean(train_rmsle_dtr))\n",
    "print('Mean RMSLE on Valid: ', np.mean(valid_rmsle_dtr))    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **The RandomForest model seems to be a slight improvement over the Decision Tree model. This will be the baseline model used for the remainder of the project.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
